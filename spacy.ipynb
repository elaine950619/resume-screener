{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufXD7bLmSMWt"
      },
      "source": [
        "# Resume Parsing with SpaCy\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, we will explore how to use **SpaCy**, a powerful NLP library in Python, to parse resumes. We'll focus on extracting key information like names, phone numbers, emails, and LinkedIn URLs.\n",
        "\n",
        "### What is SpaCy?\n",
        "SpaCy is an open-source library for advanced **Natural Language Processing (NLP)** in Python. It is designed specifically for production use and offers:\n",
        "- **Pre-trained Models**: SpaCy provides models trained on large datasets to identify entities like names, organizations, and dates.\n",
        "- **Efficiency and Speed**: Built with performance in mind, SpaCy is one of the fastest NLP libraries.\n",
        "- **Customizable Pipelines**: You can easily add or modify components like tokenizers, taggers, and entity recognizers to fit your specific needs.\n",
        "- **Wide Applications**: From text classification and sentiment analysis to information extraction and resume parsing, SpaCy is versatile and powerful.\n",
        "\n",
        "### Why Use SpaCy for Resume Parsing?\n",
        "- **Pre-trained NER models** for entity extraction\n",
        "- **Interactive and customizable** for specialized tasks like resume parsing\n",
        "- **Fast and efficient** processing for large datasets\n",
        "- **Easy integration** with other Python libraries and tools\n",
        "\n",
        "#### Helpful Resources:\n",
        "- [SpaCy Documentation](https://spacy.io/usage)\n",
        "- [Named Entity Recognition in SpaCy](https://spacy.io/usage/linguistic-features#named-entities)\n",
        "- [Custom Components in SpaCy Pipelines](https://spacy.io/usage/processing-pipelines)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bvOGEg6vSMWw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pdfplumber in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (0.11.5)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from pdfplumber) (11.1.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from pdfminer.six==20231228->pdfplumber) (44.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Requirement already satisfied: spacy in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (3.8.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (2.2.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (75.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/elaine/Documents/MDST/env/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "# Install SpaCy if you haven't already\n",
        "!pip install pdfplumber\n",
        "!pip install spacy\n",
        "!python3 -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vNeiAiKXSMWy"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "import re\n",
        "import pdfplumber"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt5VdasXSMWz"
      },
      "source": [
        "## Step 1: Load SpaCy Model\n",
        "We'll start by loading the small English model `en_core_web_sm`, which includes tokenization, POS tagging, and NER."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eNzClw9fSMW0"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6AbDgeZSMW0"
      },
      "source": [
        "## Step 2: Extract Text from a Resume PDF\n",
        "Use `pdfplumber` to extract text from the resume PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "D7KUXAXpSMW1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jake Ryan\n",
            "123-456-7890 | jake@su.edu | linkedin.com/in/jake | github.com/jake\n",
            "Education\n",
            "Southwestern University Georgetown, TX\n",
            "Bachelor of Arts in Computer Science, Minor in Business Aug. 2018 â€“ May 2021\n",
            "Blinn College Bryan, TX\n",
            "Associateâ€™s in Liberal Arts Aug. 2014 â€“ May 2018\n",
            "Experience\n",
            "Undergraduate Research Assistant June 2020 â€“ Present\n",
            "Texas A&M University College Station, TX\n",
            "â€¢ Developed a REST API using FastAPI and PostgreSQL to store data from learning management systems\n",
            "â€¢ Developed a full-\n"
          ]
        }
      ],
      "source": [
        "with pdfplumber.open(\"jakes-resume.pdf\") as pdf:\n",
        "    resume_text = \"\\n\".join([page.extract_text() for page in pdf.pages if page.extract_text()])\n",
        "\n",
        "print(resume_text[:500])  # Displaying the first 500 characters of the resume"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHqTICvjSMW2"
      },
      "source": [
        "## Step 3: Named Entity Recognition (NER)\n",
        "SpaCy's NER can recognize entities like names, organizations, and more. Let's see what it can extract from the resume.\n",
        "\n",
        "### Exercise:\n",
        "After running the code, try highlighting specific entities (like `ORG`, `PERSON`, or `GPE`) to see how well SpaCy detects them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "32YjK6VBSMW2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PERSON: Jake Ryan\n",
            "CARDINAL: 123\n",
            "ORG: TX\n",
            "DATE: Aug. 2018\n",
            "DATE: May 2021\n",
            "PERSON: Blinn College Bryan\n",
            "ORG: TX\n",
            "WORK_OF_ART: Associateâ€™s\n",
            "GPE: Liberal Arts Aug. 2014\n",
            "DATE: May 2018\n",
            "DATE: June 2020\n",
            "ORG: Texas A&M University College Station\n",
            "ORG: TX\n",
            "GPE: PostgreSQL\n",
            "PERSON: â€¢ Developed\n",
            "GPE: Flask\n",
            "GPE: React\n",
            "GPE: PostgreSQL\n",
            "PERSON: Docker\n",
            "ORG: GitHub\n",
            "ORG: â€¢ Explored\n",
            "PRODUCT: GitHub\n",
            "ORG: Information Technology Support Specialist\n",
            "DATE: Sep. 2018\n",
            "ORG: Southwestern University Georgetown\n",
            "ORG: TX\n",
            "ORG: â€¢ Assess\n",
            "CARDINAL: 200\n",
            "ORG: Artificial Intelligence Research\n",
            "DATE: May 2019\n",
            "DATE: July 2019\n",
            "ORG: Southwestern University Georgetown\n",
            "ORG: TX\n",
            "WORK_OF_ART: The Legend of Zelda\n",
            "â€¢ Developed\n",
            "PERSON: Java\n",
            "ORG: â€¢ Contributed\n",
            "CARDINAL: 50K+\n",
            "ORG: Git\n",
            "â€¢ Conducted\n",
            "ORG: â€¢ Wrote\n",
            "CARDINAL: 8\n",
            "ORG: â€¢ Presented\n",
            "ORG: the World Conference on Computational Intelligence\n",
            "Projects\n",
            "Gitlytics\n",
            "GPE: Flask\n",
            "GPE: React\n",
            "GPE: PostgreSQL\n",
            "DATE: June 2020\n",
            "GPE: Flask\n",
            "GPE: React\n",
            "PERSON: â€¢ Implemented\n",
            "WORK_OF_ART: â€¢ Used Celery\n",
            "PERSON: Redis\n",
            "PERSON: Simple Paintball\n",
            "PERSON: Spigot API\n",
            "PERSON: Java\n",
            "GPE: Maven\n",
            "PERSON: Git May 2018\n",
            "DATE: May 2020\n",
            "PRODUCT: Minecraft\n",
            "CARDINAL: 2K+\n",
            "CARDINAL: 4.5/5\n",
            "ORG: â€¢ Implemented\n",
            "ORG: Technical Skills\n",
            "Languages\n",
            "ORG: C/C++\n",
            "ORG: JavaScript\n",
            "ORG: HTML/CSS\n",
            "WORK_OF_ART: Frameworks: React\n",
            "GPE: Node.js\n",
            "GPE: Flask\n",
            "ORG: JUnit\n",
            "ORG: WordPress\n",
            "ORG: Material-UI\n",
            "PERSON: Docker\n",
            "PERSON: Cloud Platform\n",
            "PERSON: Visual Studio\n",
            "PERSON: PyCharm\n",
            "GPE: NumPy\n",
            "PERSON: Matplotlib\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(resume_text)\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(f\"{ent.label_}: {ent.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P39GjhhSMW3"
      },
      "source": [
        "## Step 4: Custom Pattern Matching with SpaCy's Matcher\n",
        "For entities like phone numbers, emails, and LinkedIn URLs, we can create custom patterns using `Matcher`.\n",
        "\n",
        "### Example Patterns:\n",
        "- **Phone Number**: Sequence of digits and optional symbols like `(`, `)`, `-`, and spaces.\n",
        "- **Email**: Text patterns with `@` symbol.\n",
        "- **LinkedIn URL**: URLs containing \"linkedin.com/in/\".\n",
        "\n",
        "### Exercise:\n",
        "Try tweaking the patterns to see if you can improve the detection of phone numbers or LinkedIn URLs. (if they don't work)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KhOg3Q5RSMW3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted Phones: ['123-456-7890']\n",
            "Extracted Emails: ['jake@su.edu']\n",
            "Extracted LinkedIn URLs: ['https://linkedin.com/linkedin.com/in/jake']\n"
          ]
        }
      ],
      "source": [
        "# Regex pattern for phone numbers\n",
        "phone_regex = r'(\\+\\d{1,2}\\s)?(\\(?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4})'\n",
        "phones = re.findall(phone_regex, resume_text)\n",
        "\n",
        "# Regex pattern for LinkedIn URLs\n",
        "linkedin_regex = r'linkedin\\.com/in/[A-Za-z0-9_\\-]+/?'\n",
        "linkedins = re.findall(linkedin_regex, resume_text)\n",
        "\n",
        "# Extract emails using SpaCy Matcher\n",
        "matcher = Matcher(nlp.vocab)\n",
        "email_pattern = [\n",
        "    {\"TEXT\": {\"REGEX\": r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\"}}\n",
        "]\n",
        "matcher.add(\"EMAIL\", [email_pattern])\n",
        "\n",
        "matches = matcher(doc)\n",
        "\n",
        "emails = []\n",
        "for match_id, start, end in matches:\n",
        "    span = doc[start:end]\n",
        "    emails.append(span.text)\n",
        "\n",
        "print(f\"Extracted Phones: {[phone[1] for phone in phones]}\")\n",
        "print(f\"Extracted Emails: {emails}\")\n",
        "print(f\"Extracted LinkedIn URLs: {[f'https://linkedin.com/{linkedin}' for linkedin in linkedins]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUnhliHVSMW3"
      },
      "source": [
        "## Step 5: Extracting Name Using NER\n",
        "SpaCy's NER can often detect the candidate's name under the `PERSON` label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1xKtVVq9SMW3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted Name: Jake Ryan\n"
          ]
        }
      ],
      "source": [
        "name = \"\"\n",
        "for ent in doc.ents:\n",
        "    if ent.label_ == \"PERSON\":\n",
        "        name = ent.text\n",
        "        break\n",
        "\n",
        "print(f\"Extracted Name: {name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3R01vQoSMW4"
      },
      "source": [
        "## Step 6: Your Turn - Extract Other Entities!\n",
        "Now it's your turn to extract other entities. Try finding:\n",
        "1. **Organizations (ORG)**\n",
        "2. **Locations (GPE)**\n",
        "3. **Dates (DATE)**\n",
        "\n",
        "### Exercise:\n",
        "Modify the code below to extract these entities and see how SpaCy performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4oOBxbz_SMW4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted Organizations: ['TX', 'TX', 'Texas A&M University College Station', 'TX', 'GitHub', 'â€¢ Explored', 'Information Technology Support Specialist', 'Southwestern University Georgetown', 'TX', 'â€¢ Assess', 'Artificial Intelligence Research', 'Southwestern University Georgetown', 'TX', 'â€¢ Contributed', 'Git\\nâ€¢ Conducted', 'â€¢ Wrote', 'â€¢ Presented', 'the World Conference on Computational Intelligence\\nProjects\\nGitlytics', 'â€¢ Implemented', 'Technical Skills\\nLanguages', 'C/C++', 'JavaScript', 'HTML/CSS', 'JUnit', 'WordPress', 'Material-UI']\n",
            "Extracted Locations: ['Liberal Arts Aug. 2014', 'PostgreSQL', 'Flask', 'React', 'PostgreSQL', 'Flask', 'React', 'PostgreSQL', 'Flask', 'React', 'Maven', 'Node.js', 'Flask', 'NumPy']\n",
            "Extracted Dates: ['Aug. 2018', 'May 2021', 'May 2018', 'June 2020', 'Sep. 2018', 'May 2019', 'July 2019', 'June 2020', 'May 2020']\n"
          ]
        }
      ],
      "source": [
        "# Example for extracting organizations\n",
        "organizations = [ent.text for ent in doc.ents if ent.label_ == \"ORG\"]\n",
        "print(f\"Extracted Organizations: {organizations}\")\n",
        "\n",
        "locations = [ent.text for ent in doc.ents if ent.label_ == \"GPE\"]\n",
        "print(f\"Extracted Locations: {locations}\")\n",
        "\n",
        "dates = [ent.text for ent in doc.ents if ent.label_ == \"DATE\"]\n",
        "print(f\"Extracted Dates: {dates}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwMS78d_SMW4"
      },
      "source": [
        "## Step 7: Combining All Extracted Information\n",
        "We'll now compile all extracted details into a structured format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0rK7e5qTSMW5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Name': 'Jake Ryan', 'Phone': '123-456-7890', 'Email': 'jake@su.edu', 'LinkedIn': 'https://linkedin.com/linkedin.com/in/jake'}\n"
          ]
        }
      ],
      "source": [
        "parsed_resume = {\n",
        "    \"Name\": name,\n",
        "    \"Phone\": phones[0][1],\n",
        "    \"Email\": emails[0],\n",
        "    \"LinkedIn\": f'https://linkedin.com/{linkedins[0]}'\n",
        "}\n",
        "\n",
        "for match_id, start, end in matches:\n",
        "    span = doc[start:end]\n",
        "    match_label = nlp.vocab.strings[match_id]\n",
        "    if match_label == \"EMAIL\":\n",
        "        parsed_resume[\"Email\"] = span.text\n",
        "\n",
        "print(parsed_resume)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME-yrDSnSMW5"
      },
      "source": [
        "## Final Thoughts\n",
        "- **SpaCy** offers powerful tools for both general and custom text extraction.\n",
        "- You can further enhance this by training a **custom NER model** for more specialized resume parsing.\n",
        "- Integrate this into larger applications to automate resume screening.\n",
        "\n",
        "Happy Parsing! ðŸš€"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
